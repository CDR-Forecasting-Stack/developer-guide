{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"CDR Forecasting Stack Technical Documentation","text":"<p>This webpage contains technical documentation for the CDR Forecasting Stack. This includes how to setup your environment to get with modeling. This also includes a handbook that outlines the code of conduct all team members must abide by.</p>"},{"location":"#support","title":"Support","text":"<p>This project is supported by Bezos Earth Fund</p>"},{"location":"code-of-conduct/","title":"Code of Conduct","text":"<p>This Code of Conduct outlines expectations for professional behavior and shared values for all members of the CDR Forecasting Stack project. These expectations apply to everyone involved in the project, without exception, including Principal Investigators, Postdoctoral Scientists, students, collaborators, and etc. This Code of Conduct applies to all project-related spaces and activities, including meetings, workshops, conferences, fieldwork, online platforms (e.g. Slack, GitHub, email), and social events associated with the project. Nothing in this Code of Conduct replaces or supersedes applicable university policies.</p> <p>The purpose of this Code of Conduct is to foster a safe, inclusive, respectful, and productive working environment. High-quality research can only be conducted when all participants feel supported and treated with dignity. </p>"},{"location":"code-of-conduct/#core-principles","title":"Core Principles","text":"<p>We are committed to:</p> <ul> <li>Mutual respect and professionalism</li> <li>Open communication and collaboration</li> <li>Transparent, reproducible, and open research</li> </ul>"},{"location":"code-of-conduct/#expected-behavior","title":"Expected Behavior","text":"<p>All participants are expected to:</p> <ul> <li>Treat colleagues with respect in all interactions, communications, and actions.</li> <li>Learn and use colleagues\u2019 names and correct pronunciations.</li> <li>Respect others\u2019 working hours, availability, and response times. While tools such as Slack or email enable rapid communication, it should not be assumed that recipients are immediately available.</li> <li>Be mindful of power dynamics. Suggestions, feedback, or requests from supervisors or senior collaborators may be perceived as directives by junior team members, even when not intended that way. Because supervisors and senior collaborators influence evaluations, funding, and authorship, their words and actions may carry more weight than intended. Those in positions of authority should take extra care to foster open discussion and to make it safe to disagree.</li> <li>Use appropriate judgment when choosing communication channels, especially for sensitive or complex matters.</li> <li>Communicate openly and clearly to avoid misunderstandings and inadvertent exclusion.</li> <li>Assume good faith in interactions and encourage addressing misunderstandings early and constructively whenever possible.</li> <li>Contribute constructively in meetings by listening actively, inviting input, and avoiding side conversations that may be distracting or exclusionary.</li> </ul>"},{"location":"code-of-conduct/#unacceptable-behavior","title":"Unacceptable Behavior","text":"<p>Unacceptable behaviors include, but are not limited to:</p> <ul> <li>Racism, sexism, ableism, or other forms of discrimination</li> <li>Hate speech, harassment, threats, or intimidation</li> <li>Unwelcome sexual attention or advances</li> <li>Personal attacks, bullying, or sustained disruptive behavior</li> <li>Retaliation against individuals who raise concerns in good faith</li> </ul>"},{"location":"code-of-conduct/#reporting-and-response","title":"Reporting and Response","text":"<p>If you experience or witness behavior that violates this Code of Conduct, you are encouraged to take one of the following steps:</p> <ul> <li>Report the concern directly to a Principal Investigator (Elizabeth, Luke, or Noah).</li> <li>Ask a trusted team member to report the concern on your behalf.</li> </ul> <p>Reports will be handled with discretion and care. Retaliation against individuals who raise concerns in good faith will not be tolerated.</p>"},{"location":"getting-started/","title":"Getting started","text":"<p>Computing is performed on Yale's Bouchet cluster. This page contains instructions on how to setup Julia on bouchet. </p>"},{"location":"getting-started/#getting-started-with-bouchet","title":"Getting started with Bouchet","text":"<p>Make sure you have an account on Bouchet! You can request an account here.</p> <p>Once an account is created you can log <code>ssh</code> into Bouchet with your net ID as the username:</p> <pre><code>ssh netid@bouchet.ycrc.yale.edu\n</code></pre> Example Login <p>For example, my net ID is <code>ljg48</code> so I would type the following into the terminal:</p> <pre><code>ssh ljg48@bouchet.ycrc.yale.edu\n</code></pre> <p>If this is your first time using Bouchet I strongly encourage you to look over Bouchet's Getting Strated pages. If you have any questions either reach out to YCRC or ask Elizabeth or Luke.</p> <p>YCRC uses the Duo multi-factor authentication (MFA), the same that is used elsewhere at Yale. To get set up with Duo, follow these instructions.</p> <p>Yale's clusters can only be accessed on the Yale network. Thus, you will need to connect to Yale's VPN before SSH'ing into Bouchet. See the ITS webpage for more details. YCRC has some recommendations for VPN software here</p>"},{"location":"getting-started/#setting-up-julia","title":"Setting up Julia","text":"<ol> <li>SSH into Bouchet with <code>ssh netid@bouchet.ycrc.yale.edu</code></li> <li>Once connected, log into the <code>devel</code> partition <code>salloc -c4 -p devel</code></li> <li>Load miniconda <code>module load miniconda</code></li> <li>Create a new <code>conda</code> enviroment, useful if you use OOD <code>conda create --name climaocean python jupyter jupyterlab</code>. Here I named it climaocean, but you can choose anything you like, and I'm adding python, jupyter, and jupyterlab</li> <li>Make the environment a kernel so you can use it with notebooks with the following command: <code>ycrc_conda_env.sh update</code></li> <li>Activate your new environment: <code>conda activate climaocean</code></li> <li>Load Julia <code>module load Julia/1.11.4-linux-x86_64</code></li> <li>Start the Julia REPL: <code>julia</code></li> <li>Once in the REPL, type <code>]</code> to go into the <code>Pkg</code> environment</li> <li>From here, type <code>add IJulia</code> to add the IJulia kernel. This is so you can use Julia with Jupyter</li> <li>Now, this next part is very important, if you start an OOD session make sure to include <code>Julia/1.11.4-linux-x86_64</code> under <code>additional modules</code> and make sure to activate the environment you just created.</li> </ol>"},{"location":"getting-started/#julia-depot-path","title":"Julia Depot Path","text":"<p>By defult, <code>~/.julia/</code> is the Julia depot path, the directory where all packages, configurations, and other Julia-related files are stored. This is set by the <code>JULIA_DEPOT_PATH</code> envionrment variable. Since there is limited space in your home directory on Bouchet, it best to change the depot to something like scratch. </p> <pre><code>DEPOT_PATH=/home/${USER}/project/JULIA_DEPOT\nmkdir -p ${DEPOT_PATH}\nexport JULIA_DEPOT_PATH=${DEPOT_PATH}\n</code></pre> Alternatively, use symlink <ol> <li>move <code>.julia</code> to scratch <code>mv /home/${USER}/.julia /home/${USER}/scratch/.julia</code> </li> <li>symlink to your home direcotry <code>ln -s /home/${USER}/project/.julia /home/${USER}/.julia</code></li> </ol>"},{"location":"getting-started/#create-a-julia-environment","title":"Create a Julia environment","text":"<ol> <li>Navigate to where you want your environment to live. I suggest a folder in your project directory</li> <li>Type <code>julia</code> to start to the REPL</li> <li>Then type <code>]</code> to start the package manager</li> <li>Type <code>activate .</code> to set the current working directory as the active environment. This creates a <code>Project.toml</code> and <code>Manifest.toml</code>, two files that include information about dependencies, versions, package names, UUIDs etc.</li> <li>Add packages to the environment: <code>add ClimaOcean OceanBioME</code></li> <li>Once that is complete, press <code>delete</code> to go to the julia repl then type <code>exit()</code> to close out the REPL</li> </ol> <p>Note</p> <p>When you add packages the the code is stored in the directory defined by <code>JULIA_DEPOT_PATH</code>.  On Bouchet this should be the scratch directory since it can get large.  The downside this directory is purged after 90 days. </p>"},{"location":"getting-started/#running-a-simple-model","title":"Running a simple model","text":"<p>Now that everything is setup, let's go through the steps of setting of a simple simulation and submitting the run to the cluseter.</p>"},{"location":"getting-started/#setup-simulation","title":"Setup simulation","text":""},{"location":"getting-started/#submit-to-cluster","title":"Submit to cluster","text":"<p>Open the note below to show the submit.sh script used to submit a job to the cluster. Copy the code store it in your project directory. If you are new to slurm, I suggest looking at the YCRC documentation</p> submission script submit.sh<pre><code>#!/bin/bash\n#SBATCH --job-name=clima\n#SBATCH --ntasks=1\n#SBATCH --time=3:00:00\n#SBATCH --account eisaman\n#SBATCH --nodes 1\n#SBATCH --mem 10G\n#SBATCH --partition gpu\n#SBATCH --gpus=a100:1\n\nmodule purge\nmodule load miniconda/24.9.2 \nmodule load Julia/1.11.4-linux-x86_64\n\n###---------------------------------------------------------\n### if true, this will instantiste the project\n### set to true only if the project is not instantiated yet\n### this will only need to be done once\n###---------------------------------------------------------\n\nINSTANTIATE=false\n\n###---------------------------------------------------------\n### path to simulation you want to run\n###---------------------------------------------------------\n\nSIMULATION=/home/${USER}/project/repos/oceananigans-coupled-global/simulations/global-simulation-dev.jl \n\n###---------------------------------------------------------\n### this is path where where Project.toml is\n### note: do not put Project.toml at end of the path\n###---------------------------------------------------------\n\nPROJECT=/home/${USER}/project/repos/oceananigans-coupled-global/\n\n###---------------------------------------------------------\n### this is where all downloaded file will live\n### will make scratch directory if does not already exist\n###---------------------------------------------------------\n\nDEPOT_PATH=/home/${USER}/project/JULIA_DEPOT\n\nmkdir -p ${DEPOT_PATH}\n\nexport JULIA_DEPOT_PATH=${DEPOT_PATH}\n\n###-------------------------------------------\n### this contains ECCO credentials\n### your ~/.ecco-credentials \n### should contain only these two lines:\n###\n### export ECCO_USERNAME=your-username\n### export ECCO_PASSWORD=your-password\n###-------------------------------------------\n\nsource /home/${USER}/.ecco-drive  \n\n###-------------------------------------------\n### instantiates packages\n### should only have to run this once\n###-------------------------------------------\n\nif ${INSTANTIATE}; then\n    julia --project=\"${PROJECT}\" -e \"using Pkg; Pkg.instantiate()\"\nfi\n\nwait\n\n###-------------------------------------------\n### runs the actual simulation\n###-------------------------------------------\n\njulia --project=${PROJECT} ${SIMULATION}\n</code></pre> <p><code>submit.sh</code> is a slurm script the tells the cluster the resources needed to run the job and what you want it to run. It is good practice to run jobs on a compute node and save unprocessed output to <code>scratch</code>. </p> <p>Submit Job To Cluster</p> submits job to cluster<pre><code>sbatch submit.sh\n</code></pre> <p>While a job is running, output logs are saved to <code>slurm-jobID.out</code>. You can <code>tail</code> this file to checkup on the running simulation.</p> <p>Check Status of a Job</p> check status of just your jobs<pre><code>squeue --me\n</code></pre> <p>Efficiency Report of Completed Job</p> show how effecient you used the resources when job completes<pre><code>seff jobID\n</code></pre> <p>Note</p> <p>The effeciency report can help you more effeciently use resources for future runs. Remember, Bouchet is a shared cluster. If you request nodes that are not being utilized then nobody else can use them until your job is complete. Be mindful of others.</p>"},{"location":"research-practices/","title":"Research Practices","text":"<p>The CDR Forecasting Stack project is committed to responsible, transparent, and reproducible research. The following practices guide research conduct, authorship, publication, and software development across the project.</p>"},{"location":"research-practices/#authorship-and-contributions","title":"Authorship and Contributions","text":"<ul> <li>Authorship will follow the Vancouver Convention.</li> <li>Author contributions will be described using the CRediT taxonomy.</li> <li>Authorship and contribution decisions should be discussed openly and revisited as projects evolve.</li> </ul>"},{"location":"research-practices/#transparency-reproducibility-and-open-research","title":"Transparency, Reproducibility, and Open Research","text":"<ul> <li>Transparency and reproducibility are core requirements of the research and publication process.</li> <li>Whenever possible, publications should be made openly available, either through open-access journals or institutional or disciplinary repositories (e.g., arXiv or Earth ArXiv).</li> <li>Data supporting publications should be made openly available whenever feasible. When full data release is not possible, reduced or derived datasets sufficient to support published results should be shared.</li> </ul>"},{"location":"research-practices/#software-data-and-licensing","title":"Software, Data, and Licensing","text":"<ul> <li>Code developed specifically within the CDR Forecasting Stack project should be hosted under the CDR Forecasting Stack GitHub organization.</li> <li>Software developed in collaboration with, but not exclusively for, the project should be open source and accessible without authentication or fee barriers.</li> <li>Private repositories may be used during active development.</li> <li>Licensing decisions remain with the original authors but should be consistent with host institution policies and adhere to the FAIR principles or the Open Source Definition.</li> <li>Recommended licenses include MIT for software and Creative Commons CC-BY for non-code products such as text, figures, and websites.</li> </ul>"}]}